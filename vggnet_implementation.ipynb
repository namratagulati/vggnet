{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSOZITO7hQEi3M1uIPnf2z"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9M3opDzawgGM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#no of filters in subsequent layers\n",
        "VGG_types_dict = {\n",
        "    \"VGG11\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
        "    \"VGG13\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
        "    \"VGG16\": [64,64,\"M\",128,128,\"M\",256,256,256,\"M\",512,512,512,\"M\",512,512,512,\"M\"],\n",
        "    \"VGG19\": [64,64,\"M\",128,128,\"M\",256,256,256,256,\"M\",512,512,512,512,\"M\",512,512,512,512,\"M\"]\n",
        "}"
      ],
      "metadata": {
        "id": "6fuEc9vYxy2O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VGGType = \"VGG16\"\n",
        "# using nn.Module class in PyTorch\n",
        "# 3 i/p channels for images with RGB color channels\n",
        "# 500:no of categories to classify the input images into\n",
        "class VGGnet(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_classes=500):\n",
        "        super(VGGnet, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.conv_layers = self.create_conv_layers(VGG_types_dict[\"VGG16\"])\n",
        "\n",
        "        #fully connected layers(FCs) of the VGGnet\n",
        "        #nn.Sequential for  chaining multiple layers\n",
        "        self.fcs = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),     #flattened input of size 512 * 7 * 7\n",
        "            nn.ReLU(),                        # for non-linearity\n",
        "            nn.Dropout(p=0.5),                #prevent overfitting\n",
        "            nn.Linear(4096, 4096),            #transforms the input from size 4096 to size 4096\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, num_classes),     #transforms the input from size 4096 to 500 classes\n",
        "        )\n",
        "    # i/p data to convolutional layers- flattened- fully connected layers\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.reshape(x.shape[0], -1)         # batch size dim changed from multi-D to a 1-D tensor.\n",
        "        x = self.fcs(x)\n",
        "        return x\n",
        "\n",
        "    def create_conv_layers(self, architecture):\n",
        "        layer = []                            # to store the convolutional layers\n",
        "        in_channels = self.in_channels        #3 input channels\n",
        "\n",
        "        for i in architecture:\n",
        "            if type(i) == int:                # convolutional layer checked via integer\n",
        "                out_channels = i\n",
        "\n",
        "                layer += [\n",
        "                    nn.Conv2d(\n",
        "                        in_channels=in_channels,\n",
        "                        out_channels=out_channels,\n",
        "                        kernel_size=(3, 3),\n",
        "                        stride=(1, 1),\n",
        "                        padding=(1, 1),\n",
        "                    ),\n",
        "                    nn.BatchNorm2d(i),        # batch normalization layer to normalize the output of the convolutional layer\n",
        "                    nn.ReLU(),\n",
        "                ]\n",
        "                in_channels = i\n",
        "            elif i == \"M\":\n",
        "                layer += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\n",
        "\n",
        "        return nn.Sequential(*layer)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model = VGGnet(in_channels=3, num_classes=500).to(device)\n",
        "    ## N = 3 (Mini batch size)i.e. samples processed together\n",
        "    x = torch.randn(3, 3, 224, 224).to(device)  #transfers the model parameters to GPU or CPU\n",
        "    print(model(x).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-ynabeKxXoz",
        "outputId": "2632917b-dc48-4de2-9123-14ebd12ddd72"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 500])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "more output channels->more detailed feature maps"
      ],
      "metadata": {
        "id": "MgH1rsnGGXYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrPv9Iymyzgi",
        "outputId": "f83409cc-8de6-44ea-bb18-d6fc7c106eb1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGGnet(\n",
            "  (conv_layers): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU()\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU()\n",
            "    (13): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU()\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU()\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU()\n",
            "    (23): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU()\n",
            "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU()\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU()\n",
            "    (33): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (36): ReLU()\n",
            "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (39): ReLU()\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU()\n",
            "    (43): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fcs): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=500, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    }
  ]
}